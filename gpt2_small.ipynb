{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (GPT2Model,GPT2LMHeadModel, \n",
    "                          GPT2Config, GPT2Tokenizer,\n",
    "                         BertConfig, BertTokenizer,\n",
    "                         BertModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary encoding some pretrained (config, tokenizer, model) options for language model:\n",
    "language_model_dict = {'bert-base-uncased': [BertConfig, BertTokenizer, BertModel],\n",
    "             'bert-base-multilingual-cased': [BertConfig, BertTokenizer, BertModel],\n",
    "              'gpt2': [GPT2Config, GPT2Tokenizer, GPT2LMHeadModel],\n",
    "              'gpt2-xl': [GPT2Config, GPT2Tokenizer, GPT2Model]\n",
    "             }\n",
    "\n",
    "# Dictionary encoding some pretrained (config, tokenizer, model) options:\n",
    "model_dict = {'bert-base-uncased': [BertConfig, BertTokenizer, BertModel],\n",
    "             'bert-base-multilingual-cased': [BertConfig, BertTokenizer, BertModel],\n",
    "              'gpt2': [GPT2Config, GPT2Tokenizer, GPT2LMHeadModel],\n",
    "              'gpt2-xl': [GPT2Config, GPT2Tokenizer, GPT2LMHeadModel]\n",
    "             }\n",
    "\n",
    "# Choose a huggingface pretrained model from the list above, and maybe other options moving forward\n",
    "config = {\"model_name\":'gpt2'}\n",
    "\n",
    "# Choose a pretrained mode\n",
    "pretrained_model = config[\"model_name\"]\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained gpt2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = model_dict[pretrained_model][1].from_pretrained(pretrained_model)\n",
    "\n",
    "# Load configuration for bert model; output all hidden states\n",
    "config = model_dict[pretrained_model][0].from_pretrained(pretrained_model, output_hidden_states=True, use_cache = False, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "# Load pretrained bert with desired config\n",
    "model = model_dict[pretrained_model][2].from_pretrained(pretrained_model, config = config)\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Language Modeling usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Use model.generate wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize some input\n",
    "tokens = tokenizer.encode(\"Can you guess what I am going to say\", return_tensors='pt')\n",
    "tokens = tokens.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you guess what I am going to say next? \"I\\'ll have to go find out.\"\\n\\nAnd then I have to go ask her'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the model to generate text beginning with previous text as context, \n",
    "# by using top-k decoding within the model.generate wrapper\n",
    "tokenizer.decode(model.generate(tokens, do_sample=True, \n",
    "    max_length=30, top_k = 20)[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Greedy decode by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the model to generate text using previous text as context,\n",
    "# by using greedy decoding directly from the LMHead model output:\n",
    "\n",
    "# Extract final output layer from the LM\n",
    "with torch.no_grad():\n",
    "    # All outputs from the Language model\n",
    "    outputs = model(tokens)\n",
    "    # The logits output for each of the input tokens:\n",
    "    predictions = outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ``predictions`` output gives a score for each element of the vocab, for each of the input tokens. This is documented in the return statement of transformers.GPT2LMHeadModel, as described here: https://huggingface.co/transformers/model_doc/gpt2.html#gpt2lmheadmodel . Our ``predictions`` is the returned ``logits`` in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 50257])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape to be sure:\n",
    "# Shape = (batch_size, num_tokens, vocab_size)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you guess what I am going to say?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Greedily generate the next word by finding the highest scoring vocab\n",
    "# item for the last token in the input.\n",
    "predicted_index = torch.argmax(predictions[0, -1, :]).reshape(1,1)\n",
    "predicted_text = tokenizer.decode(torch.cat((tokens,predicted_index), dim =1).reshape(-1))\n",
    "predicted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Token Embedding Representations from LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now chop off the head of this model, and extract the last hidden state as a sort of high level embedding. Note that by virture of the pretrained model itself, we'll get an embedding per input token in doing this, and we will need to come up with out our own determination of how to associate a single embedding to a sentence. We'll also investigate the effect of negating sentences in two ways:\n",
    " \n",
    "1.  Studying the embeddings themselves, by e.g clustering, studying norm distributions, angle distributions, etc.\n",
    "2.  Considering the differences of the word embeddings associated to (clause, negation) pairs, and then looking at the distribution of sentiments/clauses/phrases occurring when those differences are decoded by the LM head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Positive and Negative Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A statement and one possible negation.\n",
    "statement = 'This book is bad.'\n",
    "negation = 'This book is good.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_output(text, model = model, tokenizer = tokenizer, layer_num = -1,\n",
    "                         aggregation = 'average', elt_index = None):\n",
    "    \n",
    "    # Average the embeddings for each token, and return\n",
    "    if aggregation == 'average' or aggregation == 'elt':\n",
    "        # tokenize the input\n",
    "        tokens = tokenizer.encode(text, return_tensors = 'pt')\n",
    "        tokens = tokens.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # All outputs from the Language model\n",
    "            outputs = model(tokens)\n",
    "            # All hidden states\n",
    "            hidden_states = outputs[1]\n",
    "            # Hidden state from layer layer_num\n",
    "            layer = hidden_states[layer_num]\n",
    "            layer = torch.squeeze(layer)\n",
    "            \n",
    "            if aggregation == 'average':\n",
    "                if len(layer.shape) > 1:\n",
    "                    averaged_layer = torch.mean(layer, dim = 0)\n",
    "                    return averaged_layer\n",
    "                else:\n",
    "                    return layer\n",
    "                \n",
    "            if aggregation == 'elt':\n",
    "                assert elt_index is not None, 'Please specify an element index'\n",
    "                if len(layer.shape) > 1:\n",
    "                    last_elt = layer[-1]\n",
    "                    return last_elt\n",
    "                else:\n",
    "                    return layer\n",
    "        \n",
    "        \n",
    "    # Return the embeddings for each token\n",
    "    if aggregation == 'none':\n",
    "        tokens = tokenizer.encode(\n",
    "            text, \n",
    "            return_tensors = 'pt'\n",
    "            #,max_length=max_length,\n",
    "            #pad_to_max_length=True\n",
    "        )\n",
    "        tokens = tokens.to(device)\n",
    "        '''\n",
    "        Return all token embeddings, so can study each individually. For any batch processing,\n",
    "        this may require different sentiments have the same number of tokens, so we may want to set\n",
    "        a max length for sentences and pad.\n",
    "        '''\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the cosine of the angle between the last layer embeddings associated to the statement and it's negation above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9968, device='cuda:0')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_cosine(statement1, statement2, aggregation, elt_index = None):\n",
    "    statement1_vec = extract_hidden_output(statement1, aggregation = aggregation, elt_index = elt_index)\n",
    "    statement2_vec = extract_hidden_output(statement2, aggregation = aggregation, elt_index = elt_index)\n",
    "    cosine = torch.dot(statement1_vec, statement2_vec)/(torch.norm(statement1_vec)*torch.norm(statement2_vec))\n",
    "    return cosine\n",
    "\n",
    "\n",
    "compute_cosine(statement, negation, aggregation = 'average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small angle for a negation confused me at first. I suppose this is not so surprising, though, and reflects that angle has little to do with similarity in these sorts of transformer models, which in and of itself is interesting, given that it seems common for people to use cosine similarity on hidden states as if that represents similarity. Maybe a better interpretation here is that good and bad have similar angles because they are very likely to occur in similar contexts, and this model was probably trained on MLM. For example, ('turtle', 'bad') have a larger angle between them than either ('good', 'bad') or ('good', 'lovely'), which makes sense in the latter interpretation above.\n",
    "\n",
    "\n",
    "Or, perhaps the way to construct the sentence vector is not the one implemented here, and the correct one actually results in a larger angle and this example is completely inaccurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Stanford real-life contradictions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Downloaded 'real-life contradictions' from https://nlp.stanford.edu/projects/contradiction/\n",
    "tree = ET.parse('data/real_contradiction.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract contradiction pairs from the XML\n",
    "pairs = []\n",
    "for child in root:\n",
    "    pair =[]\n",
    "    attrib = child.attrib\n",
    "    if (attrib['contradiction'] =='YES') & \\\n",
    "    ((attrib['type'] == 'lexical') | (attrib['type'] == 'negation')):\n",
    "        for statement in child:\n",
    "            pair.append(statement.text)\n",
    "    pairs.append(pair)\n",
    "    \n",
    "# Remove empty rows\n",
    "pairs = [pair for pair in pairs if len(pair)>0]\n",
    "\n",
    "pairs = pd.DataFrame(pairs, columns = [\"statement\",\"negation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>negation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tariq Aziz was not considered a member of Sadd...</td>\n",
       "      <td>Tariq Aziz was in Saddam's inner circle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tariq Aziz kept outside the closed circle of S...</td>\n",
       "      <td>Tariq Aziz was in Saddam's inner circle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tariq Aziz was not one of the most powerful fi...</td>\n",
       "      <td>Tariq Aziz was prominent in the regime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tariq Aziz retained influence.</td>\n",
       "      <td>Aziz had virtually no power.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No one has been arrested in the case.\"</td>\n",
       "      <td>Collin Finnerty was arrested on charges of sex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No one has been arrested in the case.</td>\n",
       "      <td>Two sophomore Duke lacrosse players were arres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zarqawi did in fact survive the airstrike.</td>\n",
       "      <td>An airstrike ended al-Zarqawi's life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The African Union's mandate in Darfur is to mo...</td>\n",
       "      <td>The African Union will have to enforce the pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The National Security Agency carries out elect...</td>\n",
       "      <td>The eavesdropping network of the agency [NSA] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sudan will grant permission for United Nations...</td>\n",
       "      <td>Sudan is as adamant as ever that it will never...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  \\\n",
       "0  Tariq Aziz was not considered a member of Sadd...   \n",
       "1  Tariq Aziz kept outside the closed circle of S...   \n",
       "2  Tariq Aziz was not one of the most powerful fi...   \n",
       "3                     Tariq Aziz retained influence.   \n",
       "4             No one has been arrested in the case.\"   \n",
       "5              No one has been arrested in the case.   \n",
       "6         Zarqawi did in fact survive the airstrike.   \n",
       "7  The African Union's mandate in Darfur is to mo...   \n",
       "8  The National Security Agency carries out elect...   \n",
       "9  Sudan will grant permission for United Nations...   \n",
       "\n",
       "                                            negation  \n",
       "0           Tariq Aziz was in Saddam's inner circle.  \n",
       "1           Tariq Aziz was in Saddam's inner circle.  \n",
       "2            Tariq Aziz was prominent in the regime.  \n",
       "3                       Aziz had virtually no power.  \n",
       "4  Collin Finnerty was arrested on charges of sex...  \n",
       "5  Two sophomore Duke lacrosse players were arres...  \n",
       "6              An airstrike ended al-Zarqawi's life.  \n",
       "7  The African Union will have to enforce the pea...  \n",
       "8  The eavesdropping network of the agency [NSA] ...  \n",
       "9  Sudan is as adamant as ever that it will never...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store all cosines\n",
    "cosines = []\n",
    "for (statement, negation) in zip(pairs.statement.values, pairs.negation.values):\n",
    "    cosines.append(compute_cosine(statement, negation, aggregation = 'average'))\n",
    "    \n",
    "# Plot distribution of cosines among these pairs\n",
    "plt.hist(torch.stack(cosines).cpu(), bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "3.  Determine how HF gpt2 implementation constructs sentence embeddings from token embeddings.\n",
    "4.  Reproduce analogous notebook for Bert, which should be straightforward aside from a few differences in method  used to produce sentence embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
